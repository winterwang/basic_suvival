---
title: "Survival Analysis"
subtitle: "The basic ideas, models, assumptions, and something beyond"
author: "Chaochen Wang"
date: "2018/10/03 (updated: `r Sys.Date()`)"
output:
  xaringan::moon_reader:
    css: [default, "css/LSHTM.css", metropolis-fonts]
    lib_dir: libs
    nature:
      countdown: 60000
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
```

# Describing survival data (1)

<!-- ### Important assumptions:  -->

<!-- + It is assumed that censoring is uninformative about event times. -->

<!-- + This means that the time at which an individual is censored, or the fact that they are censored, does not give us any information about when that person may have the event. -->

+ We define a random variable $T$, which represents survival time.

+ The survival function 

    + The survivor function at a time $t$ is the probability that the survival time $T$ exceeds a value $t$:

$$S(t) = \text{Pr}(T>t)$$
  + Relation to the cumulative distribution function: 
    
$$
\begin{aligned}
F(t) & =  \text{Pr}(T\leqslant t) \\
     & = 1 - \text{Pr}(T>t) \\ 
     & = 1- S(t)
\end{aligned}
$$

+ The hazard function

$$
h(t) = \text{lim}_{\delta\rightarrow0}\frac{1}{\delta}\text{Pr}(t\leqslant T < t + \delta | T \geqslant t)
$$


---
class: middle

# Describing survival data (2)

- The cumulative hazard function

$$
H(t) = \int_o^th(u)du
$$


- The probability density function at time $t$:

$$
f(t) = \frac{d}{dt}F(t) = \text{lim}_{\delta\rightarrow0}\frac{1}{\delta}\text{Pr}(t\leqslant T < t + \delta)
$$
- In general, and in particular to incorporate continuous variables and adjustment for confounders, we want to use
**regression-based approaches** to analyze survival data. 

- Methods of analysis need to **handle censoring** and need to allow for the fact that **survival times are strictly non-negative**.


---
class: middle

### Relationships between functions (1)

<!-- ## $S(t), h(t), H(t), f(t)$ -->

$$
\begin{aligned}
f(t) & = \frac{\text{d}}{\text{d}t}F(t)  = \frac{\text{d}}{\text{d}t}\{ 1-S(t) \} = - \frac{\text{d}}{\text{d}t}S(t) \\
S(t) & = 1 - F(t)  = 1 - \int_0^t f(u)\text{d}u = \int_t^\infty f(u)\text{d}u \\
h(t) & = \lim_{\delta\rightarrow0}\frac{1}{\delta}\text{Pr}(t \leqslant T < t+ \delta | T > t) \\
     & = \lim_{\delta\rightarrow0}\frac{1}{\delta}\frac{\text{Pr}(t \leqslant T < t+ \delta, T > t)}{\text{Pr}(T > t)} (\text{Bayes' Theroem}) \\
     & = \lim_{\delta\rightarrow0}\frac{1}{\delta}\frac{\text{Pr}(t \leqslant T < t+ \delta)}{\text{Pr}(T > t)} = \frac{f(t)}{S(t)}\\
h(t) & = \frac{f(t)}{S(t)} = \frac{\frac{\text{d}}{\text{d}t}F(t)}{S(t)}  \\
     & = \frac{- \frac{\text{d}}{\text{d}t}S(t)}{S(t)} = -\frac{d\log[S(t)]}{dS(t)}\cdot\frac{dS(t)}{dt}  \\ 
     & = - \frac{\text{d}}{\text{d}t}\text{log}[S(t)] (\text{chain rule}) \\
\end{aligned}
$$


---
class: middle

### Relationships between functions (2)

$$
\begin{aligned}
H(t) &  = \int_0^th(u)du = \int_0^t\frac{f(u)}{S(u)}du = \int_0^t\frac{f(u)}{1-F(u)}du  \\
     & = - \int_0^t\frac{-f(u)}{1-F(u)}du = - \log[1-F(t)] = -\log[S(t)] \\ 
\Rightarrow S(t) & = \exp[-H(t)]
\end{aligned}
$$


---
class: middle
# Analysing survival data

### 1. Fully parametric methods
- Exponential distribution
- Weibull distribution
- Log-logistic distribution

### 2. Non-parametric methods 
- Kaplan-Meier estimate of the survivor function
- Life table estimates
- Log rank test
- Nelson-Aalen estimate of the cumulative hazard

### 3. Semi-parametric methods
- Cox proportional hazards model

---
class: middle
# Parametric models (1)

**Exponential distribution:** Under the exponential distribution the hazard rate is constant over time: $\lambda$

$$
\begin{aligned}
h(t) & = \lambda \\
S(t) & = \exp(-\lambda t) \\
f(t) & = \lambda\exp(-\lambda t) \\
\end{aligned}
$$
*Proportional hazard model:*
$$h(t|x) = h_0(t)\exp(\beta x) = \lambda \exp(\beta x)$$

**Weibull Distribution:**

$$
\begin{aligned}
h(t) & = \lambda\kappa t^{\kappa - 1} \\ 
S(t) & = \exp(-\lambda t^\kappa) \\ 
f(t) & = \lambda\kappa t^{\kappa - 1}\exp(-\lambda t^\kappa)
\end{aligned}
$$

*Proportional hazard model:*

$$h(t|x) = h_0(t)\exp(\beta x) = \lambda\kappa t^{\kappa - 1} \exp(\beta x)$$

---
class: middle
# Parametric models (2)


- The assumption that $\beta$ does not depend on $t$ is called the **proportional hazards assumption** -- the effect on the hazard does not change over time.

- The ratio of the hazards in the two groups is called: **Hazard ratio**
$$
\frac{h(t|x)}{h_0(t)} = \exp(\beta)
$$

- $\beta$ is called log hazard ratio

- The hazard ratio $\exp(\beta)$ does not depend on time (the **proportional hazards assumption**) -- it is **constant** over time .


---
class: middle
### Fitting Parametric models in STATA and R

- STATA: after `stset` declared

```
streg exp_var, d(exp)
streg exp_var, d(weib)

// comparing exponential and weibull distribution
qui streg exp_var, d(weib)
qui estimates store A
qui streg exp_var, d(exp)
qui estimates store B
lrtest A B, force
```

- R: 

```{r eval=FALSE}
expo00 <- survival::survreg(Surv(time, event)) ~ exp_var, 
                                   dist = "exponential", data)
expo01 <- survival::survreg(Surv(time, event)) ~ exp_var, 
                                   dist = "weibull", data)

anova(expo00, expo01) # likelihood ratio test
```



---
class: middle
# Semi-parametric model (1)

Form of a proportional hazard model:

$$
h(t|x) = h_0(t)\exp(\beta x)
$$

In fully parametric survival models (exponential distribution model, Weibull distribution model, etc.), a form is assumed for $h_0(t)$ (baseline hazard).

We have to specify a form for the baseline hazard in fully parametric survival models, which we may make mistakes.

But, 

--

- If the hazard ratio $\exp(\beta)$ is the only parameter of interest. 

--
- **Do we really care about the baseline hazard** $h_0(t)$ ?


---
class: inverse
background-image: url("./img/Idontcare.jpg")
background-position: 50% 50%
background-size: contain


---
class: middle
# Semi-parametric model (2)

- Cox (1972) <sup>1</sup> suggested that the baseline hazard could be left un-specified.

- The model for the hazard of the form is called **Cox proportional hazards model** if no form is given for the baseline hazard. 

$$
h(t|x) = h_0(t)\exp(\beta x) 
$$

- This is a **semi-parametric model** because the effect (hazard ratio) of explanatory variable $x$ on the hazard is parameterized, but $h_0(t)$ (baseline hazard) is not parameterized. 


.footnote[
[1] Cox, David R. 1972. “Models and Life-Tables Regression.” JR Stat. Soc. Ser. B 34: 187–220.]

---
class: middle
# To be semi-parametric or fully-parametric?

- The Cox model uses fewer assumptions, but a fully parametric model may **often be perfectly appropriate**.

- If an exponential or Weibull model is fine, then a Cox model is also OK.

- They will generate similar hazard ratio estimates. 

- The fully-parametric approach may give slightly more precise (smaller 95% CIs).

- But this is traded of against the concern that the baseline hazard may have been mis-specified.


---
class: inverse, middle, center
# What are we assuming?

---
class: middle
# Assumptions

1. **The proportional hazards assumption** that the explanatory variables act on survival in such a way that the hazard ratio is constant over time: $h(t|x) = h_0(t)\exp(\beta x)$ is correct.

2. The assumption that we have **correctly specified the form** for how the explanatory variables act on the hazard: $h(t|x) = h_0(t)\exp(\beta x) \text{ versus } h(t|x) = h_0(t)\exp(\beta_1 x + \beta_2 x^2)$.

3. Censoring is **uninformative** for the event of interest.

4. Individuals are **independent**.

5. We have included **all relevant** explanatory variables **including possible interactions**.


---
class: middle
### Assessing the proportional hazards assumption (plot)

- The survivor function: 

$$
S(t|x) = \exp[-H_0(t)e^{\beta x}]
$$

- Take logs and moving the minus sign: 
$$
-\log S(t|x) = -H_0(t)e^{\beta x}
$$

- Take logs again: 
$$
\log[-\log S(t|x)] = \log H_0(t) + \beta x
$$


- If $x$ is a binary (0 or 1) variable, then if we plot $\log[-\log S(t|0)]$ and $\log[-\log S(t|1)]$ against **time (or other function of time, such as log time)**, the curves for different groups should be approximately **parallel over time** if the proportional hazards assumption is met. 


---
class: middle
### Assessing the proportional hazards assumption (plot)

- In Stata, this can be easily done by the following command after `stset` survival data:

```
stphplot, by(treat)
```

- In R, a little bit working

```{r, eval=FALSE}
survfit_object <- survfit(Surv(time, event) ~ treat, data)
plot(survfit_object, fun = "cloglog", xlab = "time(logcale)", 
   ylab = "log(-logS(t))")
```

```{r echo=FALSE, out.width='70%', fig.align='center'}
knitr::include_graphics('img/prop00.png')
```

---
class: inverse, center, middle
# Strategies of doing survival analysis


---
class: middle, center
## The strategy of analysis depends on the **type of study** and on the **question of interest**

#### Experimental (randomized controlled trial) or Observational study

---
class: middle
# Randomized controlled trial

- Treatment group and a control group

- No other variables of interest except for treatment


---
class: middle
## Proposed strategy: 
1. Summarise
    1. The numbers of individuals in the two treatment groups
    2. The numbers of events and censorings in the two treatment groups
    3. median event and consoring times in the two treatment groups.
2. Present Kaplan-Meier estimates of the survivor curves.

3. Use the log rank test to assess the null hypothesis that the survivor curves in the two treatment groups are the same. 

4. Investigate using plots whether a proportional hazard assumption is appropriate in quantifying the association between treatment groups and survival.

5. If PH assumption is appropriate, fit Cox PH model (or exponential/Weibull, etc.) to estimate: hazard ratio, p value, and 95% CI.
6. Perform more formal assessments (tests) about the PH assumption

---
class: middle
# Observational studies

- Several explanatory variables that we need to consider. 
- The choice of explanatory variables to be included in a survival model depends on the aims of your investigation: 

  - Type 1: **Estimating an exposure effect** <br> We are only interested in mainly one particular exposure, but wish to control for possible confounders
  
  - Type 2: **Understanding the associations between a set of several variables and the time-to-event** <br> We are interested in the independent effects of several exposures on survival, perhaps to determine which has the greatest impact on survival.
  
  - Type 3: **Prediction modelling** <br> We wish to ous a potentially large number of explanatory variables to build a model from which we can predict survival in a new individual with given values for the explanatory variables. 


---
class: middle
## Estimating an exposure effect




---
class: middle
## Proposed strategy - preliminary investigations: 

- All analyses should start with preliminary investigations

  - Kaplan-Meier plots and log rank tests to investigate the association between **each variable and the outcome**.
  
  - Assessments of proportional hazard assumption for each variable using plots. 
  
  - Investigate the association between the **main exposure and each potential confounder**.
  
  
---
class: middle
## Proposed strategy - main analysis: 

1. Fit a survival model using only the main exposure of interest.

2. Fit further models including the main exposure and each potential confounder, **one at a time**.

3. Examine the impact of adjustment for **each confounder** on the estimated association (the HR) between the main exposure and time-to-event.

4. Assess whether there is evidence that any of the adjustment variables modify the effect of the main exposure, i.e. whether there are any interactions (gender, etc.).

5. Fit a model for the main exposure with adjustment for variables identified as confounder in stage 3, and with interaction identified in 4.

6. For any remaining variable not included in the model in 5., add them back to the model **one by one** to assess whether they are confounders in the presence of any of the other variables in the model. 

7. For the final model, include all variables used in 5. plus any additional variables identified in 6.

---
class: middle, inverse, center
## Further check: <br>Again, check whether the proportional hazard assumptions holds in the final model.
